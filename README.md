# SAC HalfCheetah Implementation

강화학습 알고리즘인 Soft Actor-Critic (SAC)을 사용하여 HalfCheetah 환경에서 자연스러운 달리기 동작을 학습하는 프로젝트입니다.

## 프로젝트 설명

이 프로젝트는 다음과 같은 주요 기능을 포함합니다:

1. **SAC 알고리즘 구현**
   - 연속적인 행동 공간 지원
   - 이중 Q-네트워크 사용
   - 자동 엔트로피 조정
   - 경험 리플레이 버퍼

2. **커스텀 HalfCheetah 환경**
   - 자연스러운 달리기 동작 유도를 위한 보상 함수 수정
   - 높이 유지 보상
   - 방향 유지 보상
   - 과도한 회전 페널티

3. **시각화 도구**
   - 학습된 에이전트의 행동 시각화
   - 실시간 렌더링 지원
   - 학습 과정 모니터링

## 주요 파일

- `sac_cheetah.py`: SAC 알고리즘 구현 및 학습 코드
- `visualize.py`: 학습된 모델 시각화 도구

## 사용 방법

1. 모델 학습:
```bash
python sac_cheetah.py
```

2. 학습된 모델 시각화:
```bash
python visualize.py
```

## 참고사항

- 학습된 모델은 `saved_models` 디렉토리에 저장됩니다.
- 체크포인트는 주기적으로 저장되며, 최종 모델과 중간 체크포인트를 모두 시각화할 수 있습니다.

## 최근 수정 내역

### 2024-01-11
1. **커스텀 환경 추가**
   - `CustomHalfCheetahEnv` 클래스 구현
   - 자세 제어를 위한 추가 보상 구현
   - 보상 함수 가중치 조정:
     * 전진 속도: 1.0
     * 높이 유지: 0.3
     * 방향 유지: 0.3
     * 회전 페널티: 0.1

2. **코드 구조 개선**
   - 환경 래퍼 패턴 적용
   - 모듈화 및 재사용성 향상
   - 주석 및 문서화 개선

### 2024-01-10
1. **렌더링 호환성 개선**
   - Matplotlib 기반 렌더링 구현
   - rgb_array 모드 지원 추가
   - 다중 체크포인트 시각화 기능

### 2024-01-09
1. **시각화 스크립트 개선**
   - 'human' 모드 렌더링 문제 해결 시도
   - 다양한 렌더링 전략 탐색
   - 에러 처리 및 로깅 강화

